{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b1761e",
   "metadata": {},
   "source": [
    "# Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2100420c",
   "metadata": {},
   "source": [
    "## 1. Importar dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d613b",
   "metadata": {},
   "source": [
    "Para criar um classificador formatar os dados da sequinte maneira:\n",
    "\n",
    "moleculas -> uma lista/array com todos os smiles do seu banco de dados\n",
    "\n",
    "classes -> uma lista/array de zeros e uns representando antibiótico e não antibiótico, respectivamente\n",
    "\n",
    "O classificador vai identificar traços das moleculas e associá-los às classes, então cada molécula deverá ter o mesmo índice que sua classe. \n",
    "\n",
    "bibliotecas sugeridas:\n",
    " - pandas\n",
    " - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80bb15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "\n",
    "#Importar dados\n",
    "df = pd.read_csv('/home/joao/documentos/IC-Joao/classificador/data_teste.csv',sep=';', encoding='latin-1')\n",
    "\n",
    "#Definir a coluna das classes\n",
    "labels = np.asarray(df.Classe)\n",
    "\n",
    "#Selecionar SMILES sem as classes\n",
    "df_selected = df.drop([\"Classe\"], axis=1)\n",
    "#df_selected.drop([2], axis=0, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47b44310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdcdc84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC[C@H]1OC(=O)[C@H](C)C(=O)[C@H](C)[C@@H](O[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN1CCN(c2c(F)cc3c(=O)c(C(=O)O)cn4c3c2SCC4)CC1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CO[C@H]1C[C@H](O[C@@H]2[C@@H](C)C(=O)O[C@H](C)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCN(CC)CCS(=O)(=O)[C@@H]1CCN2C(=O)c3coc(n3)CC(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O=C1CN(/N=C/C=C/c2ccc([N+](=O)[O-])o2)C(=O)N1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>O=C(OOC(=O)c1ccccc1)c1ccccc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>CN(C)CCN(Cc1ccccc1)c1ccccn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>CC(C)(C)c1cc(-c2cc(-c3ccc(C(=O)O)cc3)ccc2OCCO)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>CCCCCCCCN=c1ccn(CCCCCCCCCCn2ccc(=NCCCCCCCC)cc2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Smiles\n",
       "0    CC[C@H]1OC(=O)[C@H](C)C(=O)[C@H](C)[C@@H](O[C@...\n",
       "1        CN1CCN(c2c(F)cc3c(=O)c(C(=O)O)cn4c3c2SCC4)CC1\n",
       "2    CO[C@H]1C[C@H](O[C@@H]2[C@@H](C)C(=O)O[C@H](C)...\n",
       "3    CCN(CC)CCS(=O)(=O)[C@@H]1CCN2C(=O)c3coc(n3)CC(...\n",
       "4        O=C1CN(/N=C/C=C/c2ccc([N+](=O)[O-])o2)C(=O)N1\n",
       "..                                                 ...\n",
       "497                       O=C(OOC(=O)c1ccccc1)c1ccccc1\n",
       "498  C[C@@H]1C[C@H]2[C@@H]3CCC4=CC(=O)C=C[C@]4(C)[C...\n",
       "499                        CN(C)CCN(Cc1ccccc1)c1ccccn1\n",
       "500  CC(C)(C)c1cc(-c2cc(-c3ccc(C(=O)O)cc3)ccc2OCCO)...\n",
       "501  CCCCCCCCN=c1ccn(CCCCCCCCCCn2ccc(=NCCCCCCCC)cc2...\n",
       "\n",
       "[502 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b79eb0",
   "metadata": {},
   "source": [
    "## 2. Processamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72a2d85",
   "metadata": {},
   "source": [
    "### 2.1 Encoding/padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a95a1",
   "metadata": {},
   "source": [
    "Nessa etapa acontece a codificação das moleculas. Pode ser tokens, one hot vector, integer vector. Você decide.\n",
    "\n",
    "É importante que ao final do processamento todos os tokens tenham o mesmo comprimento, então um processo chamado padding precisa ser aplicado.\n",
    "\n",
    "Por convenção as variáveis em machine learning assumem esses nomes:\n",
    "\n",
    "X -> uma lista/array com todos os smiles codificados\n",
    "\n",
    "y -> uma lista/array de zeros e uns representando antibiótico e não antibiótico, respectivamente\n",
    "\n",
    "\n",
    "Bibliotecas sugeridas:\n",
    " - numpy\n",
    " - sklearn\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7338b",
   "metadata": {},
   "source": [
    "## ADIÇÕES DO TIAGO: INICIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed22321",
   "metadata": {},
   "outputs": [],
   "source": [
    "comprimentos = [len(x) for x in df_selected.Smiles.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63c8d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maior_smile = np.max(comprimentos)\n",
    "maior_smile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e46ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a34ed680",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = list(df_selected.Smiles.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56d33b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = ['Cl', 'Br', 'Na', 'Li', 'Ca', 'Al', 'Ag', 'Se', 'Mg', 'Zn', 'H', 'B', 'C', 'N', 'O', 'P', 'S', 'F', 'I', 'K', '(', ')', '[', ']', '=', '#', '@', '*', '%', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.', '/', '\\\\', '+', '-', 'c', 'n', 'o', 's', 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dec4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(smiles,table):\n",
    "    tokens_list = []\n",
    "    for smile in smiles:\n",
    "        i = 0\n",
    "        token = []\n",
    "        while i < len(smile):\n",
    "            for j in table:\n",
    "                if j == smile[i:i+len(j)]:\n",
    "                    token.append(j)\n",
    "                    i = i+len(j)\n",
    "                    break\n",
    "        while len(token) < maior_smile:\n",
    "            token.insert(0,\"A\")\n",
    "        tokens_list.append(token)\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94aea5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_tokens = tokenizer(smiles,table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77a152f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25f21172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6571c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usar integer encoding ao invez de one hot\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "tokens_encoder = LabelEncoder()\n",
    "table.append(\"A\")\n",
    "tokens_encoder.fit(table)\n",
    "tokens_int_encoded = np.array([tokens_encoder.transform(i) for i in padded_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b1e8468d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21, 21, ..., 10, 11, 26],\n",
       "       [21, 21, 21, ..., 26, 26, 10],\n",
       "       [21, 21, 21, ..., 44, 10, 37],\n",
       "       ...,\n",
       "       [21, 21, 21, ..., 45, 46, 10],\n",
       "       [21, 21, 21, ..., 26, 26, 10],\n",
       "       [21, 21, 21, ..., 45, 45, 10]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_int_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4eb7084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(502, 405)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_int_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c87b8",
   "metadata": {},
   "source": [
    "## ADIÇÕES DO TIAGO: FIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d79be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding dos labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "labels = le.transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490dd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64554a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [len(x) for x in df_selected.Smiles.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceb5dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65e6630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "CC[C@H](C)[C@H]1O[C@]2(CC[C@@H]1C)C[C@@H]1C[C@@H](C/C=C(\\C)[C@@H](O[C@H]3C[C@H](OC)[C@@H](O[C@H]4C[C@H](OC)[C@@H](O)[C@H](C)O4)[C@H](C)O3)[C@@H](C)/C=C/C=C3\\CO[C@@H]4[C@H](O)C(C)=C[C@@H](C(=O)O1)[C@]34O)O2.CO[C@H]1C[C@H](O[C@H]2[C@H](C)O[C@@H](O[C@@H]3/C(C)=C/C[C@@H]4C[C@@H](C[C@]5(CC[C@H](C)[C@@H](C(C)C)O5)O4)OC(=O)[C@@H]4C=C(C)[C@@H](O)[C@H]5OC/C(=C\\C=C\\[C@@H]3C)[C@@]45O)C[C@@H]2OC)O[C@@H](C)[C@@H]1O 405\n"
     ]
    }
   ],
   "source": [
    "#Padding\n",
    "\n",
    "#Descobrir maior smile da base de dados\n",
    "x = 0\n",
    "longest_smile = ''\n",
    "\n",
    "while x < len(df_selected.Smiles):\n",
    "    if len(df_selected.Smiles[x]) > len(longest_smile):\n",
    "        longest_smile = df_selected.Smiles[x]\n",
    "    else:\n",
    "        longest_smile = longest_smile\n",
    "    print(x)\n",
    "    x = x+1\n",
    "print(longest_smile,len(longest_smile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12ec422",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "502",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 502 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2415343601dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSmiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSmiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_smile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlista_padding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_selected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSmiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_smile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcode_padding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    351\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 502"
     ]
    }
   ],
   "source": [
    "\n",
    "#Fazer padding\n",
    "\n",
    "code_padding = 'A'\n",
    "lista_padding = []\n",
    "y = 0\n",
    "\n",
    "while y<len(df_selected.Smiles):\n",
    "    if len(df_selected.Smiles[y])<len(longest_smile):\n",
    "        lista_padding.append(df_selected.Smiles[y].rjust(len(longest_smile),code_padding))\n",
    "    y = y+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def pad_seq(smiles,tokens,paddSize):\n",
    "#     \"\"\"\n",
    "#     This function performs the padding of each SMILE.\n",
    "#     ----------\n",
    "#     smiles: Set of SMILES strings with different sizes;\n",
    "#     tokens: Set of characters;\n",
    "#     paddSize: Integer that specifies the maximum size of the padding    \n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     newSmiles: Returns the padded smiles, all with the same size.\n",
    "#     maxLength: Integer that indicates the paddsize. It will be used to perform \n",
    "#                 padding of new sequences.\n",
    "#     \"\"\"\n",
    "#     maxSmile= max(smiles, key=len)\n",
    "#     maxLength = 0\n",
    "    \n",
    "#     if paddSize != 0:\n",
    "#        maxLength = paddSize\n",
    "#     else:\n",
    "#         maxLength = len(maxSmile) \n",
    "\n",
    "#     for i in range(0,len(smiles)):\n",
    "#         if len(smiles[i]) < maxLength:\n",
    "#             smiles[i] = smiles[i] + tokens[-1]*(maxLength - len(smiles[i]))\n",
    "    \n",
    "#     return smiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc7dd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Criar vocabulário para tokenização\n",
    "atoms = [\n",
    "         'H','B', 'C', 'N', 'O', 'P', 'S', 'F', 'Cl', 'Br', 'I','Na','Li','Ca','Al','Ag','Se','Mg','K','Zn'\n",
    "        ]\n",
    "\n",
    "special = [\n",
    "        '(', ')', '[', ']', '=', '#', '@', '*', '%', '0', '1', '2',\n",
    "        '3', '4', '5', '6', '7', '8', '9', '.', '/', '\\\\', '+', '-',\n",
    "         'c', 'n', 'o', 's','p'\n",
    "        ]\n",
    "\n",
    "padding = ['G', 'A', 'E'] #Go, Padding ,End\n",
    "table = sorted(atoms, key=len, reverse=True) + special + padding\n",
    "table_len = len(table)\n",
    "\n",
    "#Funções de tokenização e criação de one-hot encode\n",
    "def tokenize(smiles):\n",
    "    N = len(smiles)\n",
    "    i = 0\n",
    "    j= 0\n",
    "    token = []\n",
    "    while (i < N):\n",
    "        for j in range(table_len):\n",
    "            symbol = table[j]\n",
    "            if symbol == smiles[i:i + len(symbol)]:\n",
    "                token.append(symbol)\n",
    "                i += len(symbol)\n",
    "                break\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05140ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_encode(trans_char): #create one hot encode table\n",
    "    transl_one_hot = {} #create dictionary\n",
    "    for i, char in enumerate(table): #create one hot encode vector for each character\n",
    "        lista = np.zeros(table_len) #create zero list for each char\n",
    "        lista[i] = 1 #set 1 on the correct position\n",
    "        transl_one_hot[char] = lista #save list in dictionary\n",
    "\n",
    "    result = np.array([transl_one_hot[s] for s in trans_char]) #find the vector corresponding to the character\n",
    "    result = result.reshape(1, result.shape[0], result.shape[1])\n",
    "    #print(\"\\nTransl_one_hot:\\n\",transl_one_hot,\"\\n\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e5cba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicação da função para obter os vetores de cada smiles\n",
    "smiles = []\n",
    "z = 0\n",
    "\n",
    "while z<len(lista_padding):\n",
    "    smiles.append(one_hot_encode(tokenize(lista_padding[z])))\n",
    "    z = z+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e895318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba9b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1e7de",
   "metadata": {},
   "source": [
    "## 3. Holdout: train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d61aa0",
   "metadata": {},
   "source": [
    "Depois do processamento, seu banco de dados precisa ser dividio em traino e teste. O _Holdout_ é o ponto de separação. Geralmente os dados são dividos em dados em 70/30. 70% para treino e 30% para teste.\n",
    "\n",
    "Agora as variáveis serão separadas pelos conjuntos criados:\n",
    "\n",
    "X_treino -> 70% dos smiles codificados\n",
    "\n",
    "X_teste  -> 30% dos smiles codificados\n",
    "\n",
    "y_treino -> 70% das classes\n",
    "\n",
    "y_teste  -> 30% das classes\n",
    "\n",
    "Bibliotecas sugeridas:\n",
    " - numpy\n",
    " - sklearn"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 6,
>>>>>>> 6e2923bb47cfb90212940abd05e7b776abc7e58c
   "id": "cf7ad2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [501, 502]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b61f762f637e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m smiles_train, smiles_test, labels_train, labels_test = train_test_split(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     test_size=0.30, random_state=42)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [501, 502]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "smiles_train, smiles_test, labels_train, labels_test = train_test_split(\n",
    "    smiles, labels, \n",
    "    test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05590073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 54, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5ac28a",
   "metadata": {},
   "source": [
    "## 4. Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e72ea0",
   "metadata": {},
   "source": [
    "Depois de preparar os dados, precisamos criar um variável que contem nosso modelo. Estude o tensoflow/keras, mais especificamente a função Sequential(), para criação dos modelos.\n",
    "\n",
    "Arquiteturas sugeridas:\n",
    "- MultiLayer Perceptron (MLP)\n",
    "- Convulional Neural Networks (CNN)\n",
    "\n",
    "Não esqueça de adicionar as métricas precision, recall, accuracy e loss. Para essa ultima, você precisa estudar sobre as funções de perda usadas para classificação binária (0,1).\n",
    "\n",
    "Depois de construído use o método .fit() para treinar seu classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(smiles_train, labels_train, epochs=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e7b42",
   "metadata": {},
   "source": [
    "## 5 Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cc5b4a",
   "metadata": {},
   "source": [
    "Apos o treinamento, estude como fazer a predição no conjunto de teste com o modelo pronto. Com esses dados em mãos você pode construir uma matriz de confusão que mostra o desempenho do seu modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb85aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(smiles_test,  labels_test, verbose=2)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26904ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4becdc612f94a8bb0dff5d75e15c4e0f92aad7eb21d53035cab6eae2de717ed4"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
